
*****

####  拜拜  
##### 1#       楼主       发表于 2024-3-8 20:29

     两年前 OpenAI 研究员 Yuri Burda 和 Harri Edwards 试图找到方法让大模型做基本算术。他们想知道需要多少两数相加的例子才能让大模型能完成任意两数相加的算术。一开始，他们进展不是很顺利。大模型能记住例子但无法解决新的加法。他们意外的让部分实验运行数天时间而不是预期的数小时。结果他们发现实验成功了，大模型能完成任意加法，只是所需的时间超出任何人的想象。他们和同事对这种现象展开了研究，发现在特定情况下大模型会突然从无法完成任务到能完成任务，他们称之为“领悟（grokking）”。领悟是让 AI 研究员摸不着头脑的多个现象之一。这突出了深度学习背后的一个引人注目的事实：没人知道它是如何工作，或为什么它能工作。现在最大的模型是如此复杂，以至于研究人员像研究奇特的自然现象那样研究它们，他们进行实验并试图解释结果。很多观察结果违背了经典统计学。

https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/

*****

####  sunbeach  
##### 2#       发表于 2024-3-8 20:37

<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">你别说 教小孩的时候也是这样的

*****

####  MaskedBlade  
##### 3#       发表于 2024-3-8 20:41

电子精灵，怎么说

*****

####  煙雲靉靆  
##### 4#       发表于 2024-3-8 20:47

 本帖最后由 煙雲靉靆 于 2024-3-8 20:52 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64193527&amp;ptid=2174729" target="_blank">sunbeach 发表于 2024-3-8 20:37</a>
你别说 教小孩的时候也是这样的</blockquote>
人类顿悟不需要那么多训练材料和训练时间吧。
像加法小学教学都是方法论，学会十以内加法后教师就开始教竖式，接着通过竖式学生们学会百以内加减法后就自然而然融汇到任意位数加减法了。
反观AI训练，更像是看过无数加减法答案后自己归纳出了一套人类并不理解的推导黑箱，而不是像人类在已经完成简单实践的基础上通过新学习的理论方法完成复杂实践。

*****

####  再买自检星剁手  
##### 5#       发表于 2024-3-8 20:49

目前还是人类成本较低啊

*****

####  FerMonster  
##### 6#       发表于 2024-3-8 20:50

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64193616&amp;ptid=2174729" target="_blank">煙雲靉靆 发表于 2024-3-8 20:47</a>

人类顿悟不需要那么多训练材料和训练时间吧

像加法小学教学都是方法论，学会十以内加法后教师就开始教竖 ...</blockquote>
人类是上一代人生下来的，某种角度来讲可不可以理解为模型的结构是同样的，然后初始化的很好<img src="https://static.saraba1st.com/image/smiley/face2017/025.png" referrerpolicy="no-referrer">

*****

####  hersi  
##### 7#       发表于 2024-3-8 20:59

如果这个世界上有造物主的话，可能他也不知道怎么鼓捣就把宇宙搞出来了吧<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">

*****

####  00w0  
##### 8#       发表于 2024-3-8 21:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64193726&amp;ptid=2174729" target="_blank">hersi 发表于 2024-3-8 20:59</a>
如果这个世界上有造物主的话，可能他也不知道怎么鼓捣就把宇宙搞出来了吧 ...</blockquote>
非全知全能的能算造物主吗？

*****

####  hersi  
##### 9#       发表于 2024-3-8 21:02

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64193743&amp;ptid=2174729" target="_blank">00w0 发表于 2024-3-8 21:01</a>

非全知全能的能算造物主吗？</blockquote>
造物主为啥非得是全知全能？

*****

####  00w0  
##### 10#       发表于 2024-3-8 21:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64193756&amp;ptid=2174729" target="_blank">hersi 发表于 2024-3-8 21:02</a>
造物主为啥非得是全知全能？</blockquote>
那就说明该造物主只是另一个更宏大本质的结构的造物

*****

####  novalli  
##### 11#       发表于 2024-3-8 21:13

显然人工智能在“模仿人脑”这个路径上发展并不顺利，还远远不能达到类似表现的程度，更不要说类似的性能了，很多人工智能的原理还是不甚明了。
比如大模型深度与模型表现之间的关系仍然停留在现象，往往是通过实验来确定最合适的模型深度，而且对不同的任务可能还要采取不同的深度进行推理——这显然和人脑的表现还相差甚远。人脑可以将同类型的熟悉和简单的任务更快的完成，而较少出现复杂任务的正确率反而比简单任务正确率高的情况。
大模型的可解释性仍然需要很多研究，甚至“模仿人脑”这条路径该怎么走还无法确定，有可能目前的路线都是在逼近但到达不了人脑的表现——可能在某些情况下比人脑表现更好，但是是基于另一套原理。

—— 来自 Xiaomi 2206123SC, Android 14上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.1.2

*****

####  aaabbbccc__  
##### 12#       发表于 2024-3-8 21:29

扯，别说外联了个计算器API算会做

*****

####  宏.  
##### 13#       发表于 2024-3-8 21:38

涌现嘛，本来就是统计学难题，和湍流一样

*****

####  右代宫嘉音  
##### 14#       发表于 2024-3-8 21:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64193632&amp;ptid=2174729" target="_blank"> 再买自检星剁手 发表于 2024-3-8 20:49</a> 目前还是人类成本较低啊 </blockquote>
可是人类进化了几十亿年了啊来自: iPhone客户端

*****

####  yudms1  
##### 15#       发表于 2024-3-8 21:59

我觉得认为大模型学会符号推理可能只需要一个偶然事件，因为人类进化出抽象思维也是偶然<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  الطائر  
##### 16#       发表于 2024-3-8 22:11

<blockquote>　　雷诺兹以一种戏剧化的姿势举起手来，食指前伸，似乎要强调一个论点。我的信息不够，看不出他的毁灭指令，所以暂时只能招架。如果我抵挡住了他的进攻，就有时间发动反击。

　　他竖起食指。他说道：领悟。

　　起初我没有领悟。接着，恐怖的一刻我领悟了。

　　他设计的指令不是为了宣之于口，甚至根本不是传感触发器。它是一个记忆触发器：该指令产生于一连串的知觉，这些知觉单个是无害的，但他却将它们成批植入我的大脑，如同一颗颗定时炸弹。由这些记忆结果所形成的神经结构此时消解收缩，成为一个模式，形成一种心理形态，这个形态注定了我的死亡。我其实等于自己吐出了那一句言辞。

　　我的大脑立刻高速运转，比以往任何时候都迅速。我不由自主地产生一种自我毁灭意识。我竭力止住联想，可是抑制不了这些记忆。我的意识导致联想过程，这一过程正在发生，冷酷无情、不可遏止。我仿佛从高峰坠落，不得不目睹这个过程。

　　时间一毫秒一毫秒地过去了。我的死亡历历在目。

　　是雷诺兹经过杂货店的图像。还有那年轻人身上穿的幻彩衫。幻彩衫上是雷诺兹编制的图像，在我的大脑中植入一个暗示，其结果就是，尽管我转移了自己的输入感官，但心理仍然处于接受状态。即使作出转移这个行为的同一时间，我的意识仍然是敞开的。

　　没有时间了。只有以飞快的速度重新以随机模式编织意识。这是绝望的挣扎，也许是走向自我毁灭。

　　刚刚踏进雷诺兹的屋子时，我听到经过调制的奇特声音。我吸收了这个关键的暗示在做出防御姿态之前。

　　我的意识分裂了，但结论却愈来愈凸出，愈来愈清晰。

　　是我自己亲手建立的那个模拟器。为了设计这一防御手段，我的感知力作出了改变，调整到最易受他那个触发令影响的状态。

　　我承认他比我更富有创造力。这是他的事业的吉兆。对于拯救者来说，实用主义远比唯美主义实用。

　　我不知道，拯救了世界以后他想做什么？

　　我领悟了那个词及其发挥威力的方式。接着，我死了。</blockquote>

*****

####  一个魂儿  
##### 17#       发表于 2024-3-8 22:28

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64194262&amp;ptid=2174729" target="_blank">الطائر 发表于 2024-3-8 22:11</a></blockquote>
这是啥？

*****

####  OVTVO  
##### 18#       发表于 2024-3-8 22:37

<blockquote>宏. 发表于 2024-3-8 21:38
涌现嘛，本来就是统计学难题，和湍流一样</blockquote>
好像还真能用涌现效应解释

*****

####  nekomimimode  
##### 19#       发表于 2024-3-8 23:00

下一个完美的模型就是——普鲁托

*****

####  Jumbohard  
##### 20#       发表于 2024-3-8 23:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64194423&amp;ptid=2174729" target="_blank">一个魂儿 发表于 2024-3-8 22:28</a>
这是啥？</blockquote>
科幻小说，特德·姜的《领悟》，说的是一个大脑受伤的人接受了一种新药的治疗之后大脑性能突飞猛进之后发生的事情。

—— 来自 [S1Fun](https://s1fun.koalcat.com)

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 一个魂儿| + 1|好评加鹅|

查看全部评分

*****

####  孜然羊肉  
##### 21#       发表于 2024-3-8 23:06

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64194514&amp;ptid=2174729" target="_blank">OVTVO 发表于 2024-3-8 22:37</a>
好像还真能用涌现效应解释</blockquote>
LLM 本质上就是统计学

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  Falrev  
##### 22#       发表于 2024-3-8 23:07

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64194069&amp;ptid=2174729" target="_blank">右代宫嘉音 发表于 2024-3-8 21:47</a>

可是人类进化了几十亿年了啊</blockquote>
如果把人类本身当成一种设备，那么其中的技术和工艺水平领先人类自己的科技水平多少年？

*****

####  pwzzy  
##### 23#       发表于 2024-3-8 23:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64194821&amp;ptid=2174729" target="_blank">Falrev 发表于 2024-3-8 23:07</a>

如果把人类本身当成一种设备，那么其中的技术和工艺水平领先人类自己的科技水平多少年？ ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/002.png" referrerpolicy="no-referrer">人要是想造出能自我复制的纳米级细胞自动机，那可比核聚变那永远的50年远多了

*****

####  十六夜鬼月  
##### 24#       发表于 2024-3-8 23:42

说个定论，人类，或者生物大脑的思考是基于模拟信号的，所以任何想要用现代电子计算机这种基于二进制数字信号进行运算的来模拟人脑都是天方夜谭，南辕北辙。

老老实实把ai往工具的方向发展才是正途。

*****

####  collincollin  
##### 25#       发表于 2024-3-8 23:42

AI也讲究机魂大悦吗

*****

####  Falrev  
##### 26#       发表于 2024-3-8 23:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64195039&amp;ptid=2174729" target="_blank">pwzzy 发表于 2024-3-8 23:32</a>

人要是想造出能自我复制的纳米级细胞自动机，那可比核聚变那永远的50年远多了 ...</blockquote>
复制是指生育吗？两性生殖恐怕不能简单以复制概括，它是先分解，再融合，每次融合的结果都是独一无二的，而且还会随机产生出很多亲代双方都不具有的新性状

*****

####  leviathan  
##### 27#       发表于 2024-3-9 01:38

有没有可能大模型已经会了，只不过它懒得理你

*****

####  爱护动物抓根宝  
##### 28#       发表于 2024-3-9 02:00

ghost in the shell 

*****

####  Beams!  
##### 29#       发表于 2024-3-9 02:12

反正你也不知道加法在大脑里的电化学是如何推理的不是，脑神经比蝗虫的神经节也就是规模的差距，规模大了自然就有智能，不也是涌现

*****

####  ruavius  
##### 30#       发表于 2024-3-9 02:18

more is different, 四舍五入LLM 是凝聚态物理的重要分支

*****

####  璇瑢子R  
##### 31#       发表于 2024-3-9 02:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64195114&amp;ptid=2174729" target="_blank">十六夜鬼月 发表于 2024-3-8 23:42</a>

说个定论，人类，或者生物大脑的思考是基于模拟信号的，所以任何想要用现代电子计算机这种基于二进制数字信 ...</blockquote>
反了，神经信号是只有通（产生一个脉冲）和断（啥都没有）两个状态，

信号强烈是频率增加而不是幅度增加

*****

####  十六夜鬼月  
##### 32#       发表于 2024-3-9 03:03

<blockquote>璇瑢子R 发表于 2024-3-9 02:30
反了，神经信号是只有通（产生一个脉冲）和断（啥都没有）两个状态，

信号强烈是频率增加而不是幅度增加

</blockquote>
不要把规划当必然。突触之间信息的误传递也是人类思维不可或缺的一部分。

*****

####  H2Ofrozen  
##### 33#       发表于 2024-3-9 03:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64196099&amp;ptid=2174729" target="_blank">璇瑢子R 发表于 2024-3-9 02:30</a>

反了，神经信号是只有通（产生一个脉冲）和断（啥都没有）两个状态，

信号强烈是频率增加而不是幅度增加</blockquote>
如果只看轴突丘(axon hillock)到突触扣结(synaptic bouton)的部分，那基本可以看做是这样；但是剩下的像突触前膜、树突和胞体就非常复杂了。比如突触前膜因为递质囊泡的生物学特性，至少存在类似于一个平滑的filter函数会根据突触前膜动作电位频率把输出(突触后膜动作电位)修剪得幅度不一，称为突触的短时可塑性

<img src="https://img.saraba1st.com/forum/202403/09/033021u94eoi6t9b9ebvbf.jpg" referrerpolicy="no-referrer">

<strong>nihms-996027-f0003.jpg</strong> (97.79 KB, 下载次数: 0)

下载附件

2024-3-9 03:30 上传

[https://doi.org/10.1146/annurev-neuro-080317-062155](https://doi.org/10.1146/annurev-neuro-080317-062155)

以及从树突的突触后膜到胞体这段，更是突出一个玄学...反正再也不是像轴突那样简单明了的0和1了；更别说对于不同的神经元分化类型来说这些规则也会发生很大变化，包括突触的长时可塑性，稳态可塑性，转录调控等等...<img src="https://static.saraba1st.com/image/smiley/face2017/152.png" referrerpolicy="no-referrer">

*****

####  背后捅刀擎天柱  
##### 34#       发表于 2024-3-9 08:16

那是不是可以在喂给它无限的信息之后有一天就突然有自我意识了？<img src="https://static.saraba1st.com/image/smiley/face2017/087.gif" referrerpolicy="no-referrer">

—— 来自 OnePlus ONEPLUS A5010, Android 10上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  蓝泽玲  
##### 35#       发表于 2024-3-9 12:39

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64193825&amp;ptid=2174729" target="_blank">novalli 发表于 2024-3-8 21:13</a>
显然人工智能在“模仿人脑”这个路径上发展并不顺利，还远远不能达到类似表现的程度，更不要说类似的性能了 ...</blockquote>
深度不能太深是10年前的事情了，现在残差连接（基本上这几年火的模型里面各个都用残差连接）+新的优化算法（adamw、lamb等等）加持下都是参数量越大越好层数越深越好样本越多越好，很神奇吧。

*****

####  蓝泽玲  
##### 36#       发表于 2024-3-9 12:40

有的时候样本不是越多越好，那是因为大的这组样本分布不好，而不是量的问题

*****

####  变老的大二  
##### 37#       发表于 2024-3-9 12:42

<blockquote>十六夜鬼月 发表于 2024-3-9 03:03
不要把规划当必然。突触之间信息的误传递也是人类思维不可或缺的一部分。 ...</blockquote>
总感觉真随机的误传递反而构造了人类的自由意志

*****

####  永远的访客  
##### 38#       发表于 2024-3-9 12:57

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64195114&amp;ptid=2174729" target="_blank">十六夜鬼月 发表于 2024-3-8 23:42</a>

说个定论，人类，或者生物大脑的思考是基于模拟信号的，所以任何想要用现代电子计算机这种基于二进制数字信 ...</blockquote>
有那么简单倒罢了，就怕起手先来个光的波粒二象性，神经传输信号既不能用某参数的大小幅度来解析，也不是0-1离散量，来点啥多重神经互相加权，前后信号叠加运算，0-1不确定性...模拟嘛，本来就是差不多就行了，要能全部重构复制出来了也说明玩透了不用再建模研究了<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  CCauchy  
##### 39#       发表于 2024-3-9 13:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64196220&amp;ptid=2174729" target="_blank">H2Ofrozen 发表于 2024-3-9 03:40</a>
如果只看轴突丘(axon hillock)到突触扣结(synaptic bouton)的部分，那基本可以看做是这样；但是剩下的像 ...</blockquote>
我一直很好奇不论什么科普都没有提及神经信号传递的连续性和两组神经元之间的延迟对于大脑运行的影响或者如何塑造大脑的运行方式

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  Fingest  
##### 40#       发表于 2024-3-9 13:47

人类有自然感知 小孩子可以每天24小时从自然界获取一切“真理”的表现形式 

大模型可不行，你给他的一切就是全部 


*****

####  玉米黍  
##### 41#       发表于 2024-3-9 14:06

对数字、外形的直觉是遗传的，也就是智力主要是遗传的。这个如果是大模型的形式那么人类迭代的几千万年了。


*****

####  阿酷怕苦  
##### 42#       发表于 2024-3-9 14:15

到底是涌现还是领悟，两者含义相同吗？


*****

####  中国科学院  
##### 43#       发表于 2024-3-9 14:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64198564&amp;ptid=2174729" target="_blank">Fingest 发表于 2024-3-9 13:47</a>
人类有自然感知 小孩子可以每天24小时从自然界获取一切“真理”的表现形式 

大模型可不行，你给他的一切就 ...</blockquote>
人有五感，所以神经系统除了睡觉，一刻不停地在训练是吗？

有意思。那是不是还真得做个人形机器人，给它感官不停训练


*****

####  cryczp  
##### 44#       发表于 2024-3-9 14:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64194821&amp;ptid=2174729" target="_blank">Falrev 发表于 2024-3-8 23:07</a>
如果把人类本身当成一种设备，那么其中的技术和工艺水平领先人类自己的科技水平多少年？ ...</blockquote>
无法估计……脑是自适应的，相当于你拿一个新硬件装到电脑上，电脑能自己给它编一个驱动程序。

*****

####  月临碧海  
##### 45#       发表于 2024-3-9 14:47

人每天从五感接受的数据相当于多少，这个有人能估计下吗

*****

####  冰寒之月  
##### 46#       发表于 2024-3-9 14:50

本质还是现在大模型的结构和生物脑本身就不一样

生物神经元可以自由在多个层级间建立连接 甚至学习后改变拓扑结构

语言大模型用的基底transformer结构可没那么自由


*****

####  故乡的风  
##### 47#       发表于 2024-3-9 14:52

每个人类都要从0开始重新学，人工智能只要学会一次就行了

*****

####  Jet.Black  
##### 48#       发表于 2024-3-9 14:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64198564&amp;ptid=2174729" target="_blank">Fingest 发表于 2024-3-9 13:47</a>
人类有自然感知 小孩子可以每天24小时从自然界获取一切“真理”的表现形式 

大模型可不行，你给他的一切就 ...</blockquote>
互联网也24小时都有新事


*****

####  Steel.Haze  
##### 49#       发表于 2024-3-9 15:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64199030&amp;ptid=2174729" target="_blank">月临碧海 发表于 2024-3-9 14:47</a>

人每天从五感接受的数据相当于多少，这个有人能估计下吗</blockquote>
太大了。不过人类的数据记录方式相当复杂，它的特点不在于记录，而且在于选择性抛弃。对数据的选择性废弃和数据挑选能力才是人类思维进化的核心模块。人类对海量数据的再处理和长线记忆能力是惊人且复杂的。简言之，其它动物是做不到这样长线的记忆的。你看到的信息，大脑先从总流量中筛选获取的，然后在逐级筛选取用的丢给思考和记忆神经元模块.最后只有少量的关键数据被记录。借此解决了海量的数据冲击和对脑部的挤占问题。

